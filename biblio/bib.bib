@book{treveil2020introducing,
    title={Introducing MLOps},
    author={Treveil, M. and Omont, N. and Stenac, C. and Lefevre, K. and Phan, D. and Zentici, J. and Lavoillotte, A. and Miyazaki, M. and Heidmann, L.},
    isbn={9781098116446},
    url={https://books.google.be/books?id=BioMEAAAQBAJ},
    year={2020},
    publisher={O'Reilly Media}
}
@book{gift2021practical,
    title={Practical MLOps},
    author={Gift, N. and Deza, A.},
    isbn={9781098102982},
    url={https://books.google.be/books?id=J99CEAAAQBAJ},
    year={2021},
    publisher={O'Reilly Media}
}
@INPROCEEDINGS{mlops-definition-tools-and-challenge,
    author={Symeonidis, Georgios and Nerantzis, Evangelos and Kazakis, Apostolos and Papakostas, George A.},
    booktitle={2022 IEEE 12th Annual Computing and Communication Workshop and Conference (CCWC)},
    title={MLOps - Definitions, Tools and Challenges},
    year={2022},
    volume={},
    number={},
    pages={0453-0460},
    keywords={Training;Conferences;Computational modeling;Machine learning;Production;Market research;Robustness;MLOps;AutoML;machine learning;Deployment;re-training;monitoring;explainability;robustness;sustainability;fairness},
    doi={10.1109/CCWC54503.2022.9720902}
}
@INPROCEEDINGS{mlops-maturity-model,
    author={John, Meenu Mary and Olsson, Helena Holmström and Bosch, Jan},
    booktitle={2021 47th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)},
    title={Towards MLOps: A Framework and Maturity Model},
    year={2021},
    volume={},
    number={},
    pages={1-8},
    keywords={Embedded systems;Systematics;Bibliographies;Companies;Machine learning;Software;Software engineering;MLOps;Framework;Maturity Model;SLR;GLR;Validation Study},
    doi={10.1109/SEAA53835.2021.00050}
}
@article{DBLP:journals/corr/abs-2103-08942,
    author       = {Sasu M{\"{a}}kinen and
                  Henrik Skogstr{\"{o}}m and
                  Eero Laaksonen and
                  Tommi Mikkonen},
    title        = {Who Needs MLOps: What Data Scientists Seek to Accomplish and How Can
                  MLOps Help?},
    journal      = {CoRR},
    volume       = {abs/2103.08942},
    year         = {2021},
    url          = {https://arxiv.org/abs/2103.08942},
    eprinttype    = {arXiv},
    eprint       = {2103.08942},
    timestamp    = {Tue, 23 Mar 2021 16:29:47 +0100},
    biburl       = {https://dblp.org/rec/journals/corr/abs-2103-08942.bib},
    bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@ARTICLE{10855428,
    author={Woźniak, Adrian P. and Milczarek, Mateusz and Woźniak, Joanna},
    journal={IEEE Access},
    title={MLOps Components, Tools, Process, and Metrics: A Systematic Literature Review},
    year={2025},
    volume={13},
    number={},
    pages={22166-22175},
    keywords={Databases;Measurement;Systematic literature review;Computer architecture;Unified modeling language;Production;Reliability;Monitoring;DevOps;Containers;Architecture;machine learning operations;MLOps},
    doi={10.1109/ACCESS.2025.3534990}}
@ARTICLE{9792270,
    author={Testi, Matteo and Ballabio, Matteo and Frontoni, Emanuele and Iannello, Giulio and Moccia, Sara and Soda, Paolo and Vessio, Gennaro},
    journal={IEEE Access},
    title={MLOps: A Taxonomy and a Methodology},
    year={2022},
    volume={10},
    number={},
    pages={63606-63618},
    keywords={Pipelines;Production;Monitoring;Training;Business;Automation;Surgery;MLOps;continuous monitoring;continuous integration;continuous delivery;continuous training;XAI;sustainability},
    doi={10.1109/ACCESS.2022.3181730}}
@INPROCEEDINGS{10690392,
    author={Panchal, Deven and Verma, Prafulla and Baran, Isilay and Hsiung, Teyu and Musgrove, Dan and Lu, David},
    booktitle={2024 10th International Conference on Smart Computing and Communication (ICSCC)},
    title={Reusable MLOps: Reusable Deployment, Reusable Infrastructure and Hot-Swappable AI models and services},
    year={2024},
    volume={},
    number={},
    pages={645-651},
    keywords={Computational modeling;Pipelines;Microservice architectures;Production;Manuals;Machine learning;Data models;MLOps;Reusable MLOps;Artificial Intelligence;Machine Learning;Acumos;Open Source;AI4EU},
    doi={10.1109/ICSCC62041.2024.10690392}}
@INPROCEEDINGS{10346079,
    author={Panchal, Deven and Baran, Isilay and Musgrove, Dan and Lu, David},
    booktitle={2023 IEEE International Conference on Internet of Things and Intelligence Systems (IoTaIS)},
    title={MLOps: Automatic, Zero-Touch and Reusable Machine Learning Training and Serving Pipelines},
    year={2023},
    volume={},
    number={},
    pages={175-181},
    keywords={Training;Cloud computing;Forensics;Pipelines;Production;Software;Data models;Acumos;Machine Learning;Deep Learning;MLOps;Platform;ML Pipelines;Microservices;Nifi;Reusable ML;Open Source;AI4EU},
    doi={10.1109/IoTaIS60147.2023.10346079}}
@article{Kreuzberger2022MachineLO,
    title={Machine Learning Operations (MLOps): Overview, Definition, and Architecture},
    author={Dominik Kreuzberger and Niklas K{\"u}hl and Sebastian Hirschl},
    journal={IEEE Access},
    year={2022},
    volume={11},
    pages={31866-31879},
    url={https://api.semanticscholar.org/CorpusID:248524628}
}
@article{10.1145/3533378,
    author = {Paleyes, Andrei and Urma, Raoul-Gabriel and Lawrence, Neil D.},
    title = {Challenges in Deploying Machine Learning: A Survey of Case Studies},
    year = {2022},
    issue_date = {June 2023},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {55},
    number = {6},
    issn = {0360-0300},
    url = {https://doi.org/10.1145/3533378},
    doi = {10.1145/3533378},
    abstract = {In recent years, machine learning has transitioned from a field of academic research interest to a field capable of solving real-world business problems. However, the deployment of machine learning models in production systems can present a number of issues and concerns. This survey reviews published reports of deploying machine learning solutions in a variety of use cases, industries, and applications and extracts practical considerations corresponding to stages of the machine learning deployment workflow. By mapping found challenges to the steps of the machine learning deployment workflow, we show that practitioners face issues at each stage of the deployment process. The goal of this article is to lay out a research agenda to explore approaches addressing these challenges.},
    journal = {ACM Comput. Surv.},
    month = dec,
    articleno = {114},
    numpages = {29},
    keywords = {sofware deployment, Machine learning applications}
}
@article{LIU2020704,
    title = {Building A Platform for Machine Learning Operations from Open Source Frameworks},
    journal = {IFAC-PapersOnLine},
    volume = {53},
    number = {5},
    pages = {704-709},
    year = {2020},
    note = {3rd IFAC Workshop on Cyber-Physical & Human Systems CPHS 2020},
    issn = {2405-8963},
    doi = {https://doi.org/10.1016/j.ifacol.2021.04.161},
    url = {https://www.sciencedirect.com/science/article/pii/S2405896321003013},
    author = {Yan Liu and Zhijing Ling and Boyu Huo and Boqian Wang and Tianen Chen and Esma Mouine},
    keywords = {Machine Learning, DevOps, Software Architecture, Open Source},
    abstract = {Machine Learning Operations (MLOps) aim to establish a set of practices that put tools, pipelines, and processes to build fast time-to-value machine learning development projects. The lifecycle of machine learning project development encompasses a set of roles, stacks of software frameworks and multiple types of computing resources. Such complexity makes MLOps support usually bundled with commercial cloud platforms that is referred as vendor lock. In this paper, we provide an alternative solution that devises a MLOps platform with open source frameworks on any virtual resources. Our MLOps approach is driven by the development roles of machine learning models. The tool chain of our MLOps connects to the typical CI/CD workflow of machine learning applications. We demonstrate a working example of training and deploying a machine learning model for the application of detecting software repository code vulnerability.}
}
@INPROCEEDINGS{8804457,
    author={Amershi, Saleema and Begel, Andrew and Bird, Christian and DeLine, Robert and Gall, Harald and Kamar, Ece and Nagappan, Nachiappan and Nushi, Besmira and Zimmermann, Thomas},
    booktitle={2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)},
    title={Software Engineering for Machine Learning: A Case Study},
    year={2019},
    volume={},
    number={},
    pages={291-300},
    keywords={Software;Machine learning;Software engineering;Buildings;Organizations;Data models;artifical intelligence;machine learning;software engineering;process;data},
    doi={10.1109/ICSE-SEIP.2019.00042}}
@inproceedings{inproceedings,
    author = {Garg, Satvik and Pundir, Pradyumn and Rathee, Geetanjali and Gupta, Pradeep and Garg, Somya and Ahlawat, Saransh},
    year = {2021},
    month = {12},
    pages = {25-28},
    title = {On Continuous Integration / Continuous Delivery for Automated Deployment of Machine Learning Models using MLOps},
    doi = {10.1109/AIKE52691.2021.00010}
}
@article{10.1145/3555803,
    author = {Li, Bo and Qi, Peng and Liu, Bo and Di, Shuai and Liu, Jingen and Pei, Jiquan and Yi, Jinfeng and Zhou, Bowen},
    title = {Trustworthy AI: From Principles to Practices},
    year = {2023},
    issue_date = {September 2023},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {55},
    number = {9},
    issn = {0360-0300},
    url = {https://doi.org/10.1145/3555803},
    doi = {10.1145/3555803},
    abstract = {The rapid development of Artificial Intelligence (AI) technology has enabled the deployment of various systems based on it. However, many current AI systems are found vulnerable to imperceptible attacks, biased against underrepresented groups, lacking in user privacy protection. These shortcomings degrade user experience and erode people’s trust in all AI systems. In this review, we provide AI practitioners with a comprehensive guide for building trustworthy AI systems. We first introduce the theoretical framework of important aspects of AI trustworthiness, including robustness, generalization, explainability, transparency, reproducibility, fairness, privacy preservation, and accountability. To unify currently available but fragmented approaches toward trustworthy AI, we organize them in a systematic approach that considers the entire lifecycle of AI systems, ranging from data acquisition to model development, to system development and deployment, finally to continuous monitoring and governance. In this framework, we offer concrete action items for practitioners and societal stakeholders (e.g., researchers, engineers, and regulators) to improve AI trustworthiness. Finally, we identify key opportunities and challenges for the future development of trustworthy AI systems, where we identify the need for a paradigm shift toward comprehensively trustworthy AI systems.},
    journal = {ACM Comput. Surv.},
    month = jan,
    articleno = {177},
    numpages = {46},
    keywords = {accountability, privacy protection, fairness, reproducibility, transparency, explainability, generalization, robustness, Trustworthy AI}
}
@INPROCEEDINGS{10245408,
    author={Jain, Samridhi and Kumar, Puneet},
    booktitle={2023 International Conference on Data Science and Network Security (ICDSNS)},
    title={Cost Effective Generic Machine Learning Operation: A Case Study},
    year={2023},
    volume={},
    number={},
    pages={1-6},
    keywords={Industries;Costs;Pipelines;Organizations;Machine learning;Network security;Data science;MLOps;ML pipeline;cloud platform;Low Budget Architecture;ML Engineering},
    doi={10.1109/ICDSNS58469.2023.10245408}}

@article{gitops,
    author = {RedHat},
    title  = {What is a GitOps workflow},
    year   = {2024},
    url    = {https://www.redhat.com/en/topics/devops/what-is-gitops-workflow}
}
@software{Kubeflow,
    title = {Kubeflow},
    url = {https://www.kubeflow.org/},
}
@software{argo,
    title = {Argo},
    url = {https://argoproj.github.io/},
}
@software{airflow,
    title = {Airflow},
    url = {https://airflow.apache.org/},
}
@software{docker,
    title = {Docker},
    url = {https://www.docker.com/},
}
@article{RODRIGUES2025104169,
    title = {A MLOps architecture for near real-time distributed Stream Learning operation deployment},
    journal = {Journal of Network and Computer Applications},
    pages = {104169},
    year = {2025},
    issn = {1084-8045},
    doi = {https://doi.org/10.1016/j.jnca.2025.104169},
    url = {https://www.sciencedirect.com/science/article/pii/S1084804525000669},
    author = {Miguel G. Rodrigues and Eduardo K. Viegas and Altair O. Santin and Fabricio Enembreck},
    keywords = {MLOps, Stream Learning, Kubernetes, Microservices},
    abstract = {Traditional architectures for implementing Machine Learning Operations (MLOps) usually struggle to cope with the demands of Stream Learning (SL) environments, where deployed models must be incrementally updated at scale and in near real-time to handle a constantly evolving data stream. This paper proposes a new distributed architecture adapted for deploying and updating SL models under the MLOps framework, implemented twofold. First, we structure the core components as microservices deployed on a container orchestration environment, ensuring low computational overhead and high scalability. Second, we propose a periodic model versioning strategy that facilitates seamless updates of SL models without degrading system accuracy. By leveraging the inherent characteristics of SL algorithms, we trigger the model versioning task only when their decision boundaries undergo significant adjustments. This allows our architecture to support scalable inference while handling incremental SL updates, enabling high throughput and model accuracy in production settings. Experiments conducted on a proposal’s prototype implemented as a distributed microservice architecture on Kubernetes attested to our scheme’s feasibility. Our architecture can scale inference throughput as needed, delivering updated SL models in less than 2.5 s, supporting up to 8 inference endpoints while maintaining accuracy similar to traditional single-endpoint setups.}
}