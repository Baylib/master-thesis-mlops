\section{Tools and Frameworks}\label{sec:tools}

In this section we will present some of the tools that the literature recommend to implement MLOps workflow.

\subsection{Docker}\label{subsec:docker}
Docker\cite{docker} is a containerization platform that packages applications and their dependencies into isolated,
lightweight containers, ensuring consistent and portable execution across different environments.

Docker is essential for MLOps because it ensures consistent and reliable deployment of machine learning models across different environments.
By containerizing models with all their dependencies, Docker avoids conflicts between incompatible versions and isolates resource usage,
preventing one model from disrupting others.
This makes Docker a key tool for efficient, scalable, and reproducible ML deployments.\cite{treveil2020introducing}(p.80)

Docker is not the only containerization platform out there, but it's almost became a common noun nowadays for containerized applications.

\subsection{Kubernetes}\label{subsec:kubernetes2}

Kubernetes\cite{kubernetes} is a container orchestration platform that automates the deployment, scaling, and management of containerized applications.
It enables infrastructure as code through tools like Helm, simplifying application deployment and configuration.
By using features such as namespaces, resource quotas, and specialized node types (e.g., GPU nodes for machine learning),
Kubernetes allows multiple teams to securely share resources while maintaining isolation.
Its portability ensures compatibility across various Kubernetes providers, making it a flexible and scalable solution for diverse projects.

Docker with Kubernetes together simplifies deployment strategies and enables scalable hosting of ML models,
though it lacks native ML performance management capabilities on its own.\cite{treveil2020introducing}(p.81)

\subsection{Version Control and CI/CD Pipelines}\label{subsec:version-control-and-ci/cd-pipelines}
Majority of the article we found in the literature are using Git and particularly GitHub\cite{github} as their collaborative development platform.
Github uses Github Actions to define their CI/CD pipelines.

\subsection{Apache Airflow}\label{subsec:apache-airflow}
Apache Airflow\cite{airflow} is a platform created by the community to programmatically author, schedule and monitor workflows\cite{airflow}
It's a general pipeline tool that can be deployed on Kubernetes.
It's mainly used as a DataOps workflow orchestrator in publications about MLOps\cite{???,10245408}

An Airflow \textit{DAG} (Directed Acyclic Graph) is the core concept of Airflow\cite{airflow}.
It's used to define pipelines as tasks that are organized with relationships.
We will show examples later in this paper.

Airflow offers connector with Opensearch which can be deployed as a dependency to Airflow.

\subsection{Kubeflow}\label{subsec:kubeflow2}
Kubeflow\cite{Kubeflow} is an open-source platform designed to simplify the deployment, management, and scaling of machine learning workflows on Kubernetes.
It provides tools for building portable, scalable, and efficient ML pipelines, including components for training, hyperparameter tuning, and serving models.
Kubeflow is used or mention in many publication and MLOps platforms\cite{inproceedings,10855428}

Kubeflow integrate S3-storage which is often cited to be used as a model repository as in\cite{BURGUENOROMERO2025107499}.

\subsection{Databricks}

Is another platform to orchestrate MLOps workflows.
It's a Data-centric approach to establish and scale machine learning specialized into MLOps for large language models LLM.
\url{https://blog.infocruncher.com/resources/ml-productionisation/The%20Big%20Book%20of%20MLOps%20(Databricks,%20v6,%202022).pdf}
\url{https://docs.databricks.com/aws/en/machine-learning/mlops/mlops-workflow}

Databricks is a unified data analytics platform that integrates data engineering, data science, and machine learning workflows.

In an MLOps context, It provides an end-to-end MLOps platform with MLflow integration for experiment tracking, model registry, and deployment
Features automated CI/CD pipelines specifically optimized for ML workflows
Offers Delta Lake for reliable data management with ACID transactions
Includes feature store capabilities for feature engineering and sharing
Supports both batch and real-time serving for ML models

Cited by \cite{mlflow}.

\subsection{Airbytes}
Airbyte is an open-source data integration platform focused on ETL/ELT processes.

\begin{itemize}
\item Provides pre-built connectors for data sources and destinations
\item Features a centralized configuration for data pipelines
\item Offers incremental data syncing capabilities
\item Includes data transformation capabilities using SQL and dbt
\item Integrates with data catalogs and lineage tools
\end{itemize}

While primarily a data engineering tool, Airbyte plays a crucial role in MLOps by ensuring quality data ingestion into ML pipelines.

\subsection{Argo}\label{subsec:argo}\cite{argo}
It's a suite of open-source tools for Kubernetes, designed to improve workflows, deployments, and continuous delivery.

We are particularly interested with ArgoCD and Argo Rollouts which are both mentioned and used in the literature.
Kubeflow uses Argo for its deployment capabilities.

\begin{itemize}
    \item ArgoCD
     is a declarative, GitOps-based continuous delivery tool for Kubernetes.
     It automates application deployments by syncing the desired state
     defined in a Git repository with the actual state in the cluster,
     ensuring consistency and enabling easy rollbacks.

    \item Argo Rollouts
     is a Kubernetes controller that provides advanced deployment strategies
     like canary and blue-green rollouts.
     It allows for progressive delivery, enabling safer and more controlled updates by gradually
     shifting traffic to new versions while monitoring their performance.

    \item Argo Workflow
    is a workflow orchestrator for Kubernetes.
    It's used by Kubeflow to orchestrate MLOps pipelines.

\end{itemize}

\subsection{Open-Metadata}\label{subsec:openmetadata}

Open-Metadata is a platform that can also be used to orchestrate DataOps workflow or even MLops workflow.
It depends on OpenSearch as an observability tool and airflow for pipeline orchestration.

\subsection{MLflow}\url{https://mlflow.org/docs/latest/}
MLflow is an open-source platform for managing the ML lifecycle, including experimentation, reproducibility,
deployment, and a central model registry.\cite{mlflow}

\subsection{ZenML}
ZenML is an extensible, open-source MLOps framework for creating portable, production-ready ML pipelines cited by\cite{blockchain-mlops}.

