\section{Tools and Platforms}\label{sec:tools}

In this section we will present some of the tools that the literature recommend to implement MLOps workflow.

\subsection{Version Control and CI/CD Pipelines}\label{subsec:version-control-and-ci/cd-pipelines}
Majority of the article we found in the literature are using Git and particularly GitHub\cite{github} as their collaborative development platform.
Github uses Github Actions to define their CI/CD pipelines.
It offers the possibility to host self-hosted runners to run private pipelines on premise.
Azure devops, Gitlab, Gitea and Bamboo pipelines can also be found in some articles\cite{Kreuzberger2022MachineLO}

\subsection{Apache Airflow}\label{subsec:apache-airflow}
Apache Airflow\cite{airflow} is a platform created by the community to programmatically author, schedule and monitor workflows\cite{airflow}.
It's a general pipeline tool that can be deployed on Kubernetes.
It can also be used for ML workflow orchestration\cite{Kreuzberger2022MachineLO}.

Defining a general MLOps workflow with explicit input-output interfaces is a good practice because it reduces common failure modes and improves clarity.
Tools like Apache Airflow can then better manage execution by identifying independent tasks and running them in parallel,leading to more efficient and reliable workflows.\cite{mlflow}
It can be used as a DataOps/MLOps workflow orchestrator\cite{10245408,mlflow}.

An Airflow \textit{DAG} (Directed Acyclic Graph) is the core concept of Airflow\cite{Kreuzberger2022MachineLO, airflow}.
It's used to define pipelines as tasks that are organized with relationships.


\subsection{Kubeflow}\label{subsec:kubeflow2}
Kubeflow\cite{Kubeflow} is an open-source platform designed to simplify the deployment, management, and scaling of machine learning workflows on Kubernetes.
It provides tools for building portable, scalable, and efficient ML pipelines, including components for training, hyperparameter tuning, and serving models.
Kubeflow is used or mention in many publication and MLOps platforms\cite{inproceedings,10855428,Kreuzberger2022MachineLO}

Kubeflow is a platform with 6 components that can be used as standalone component\cite{Kubeflow}.
\begin{itemize}
    \item Pipelines (KFP) to implement and run MLOps pipelines.
    \item Notebooks for web based development.
    \item Kubeflow Central Dashboard integrate together all Kubeflow components within a single web interface.
    \item Model Training (Kubeflow Trainer) to ease integration with python machine learning frameworks like tensorflow and more.
    \item AutoML (Katib)
    \item Model Serving (Kserve) to help delivery and deployments to production.
\end{itemize}

Kubeflow offer a Domain Specific Language as a python library to orchestrate the workflow.
Kubeflow pipeline integrate with S3-storage (Amazon Simple Storage Service) which is a standard storage solution used as a model repository like in\cite{BURGUENOROMERO2025107499}.
We'll investigate the kubeflow pipelines and storage later in this paper.

\subsection{Databricks}\label{subsec:databricks}

Is another platform to orchestrate MLOps workflows.
It's a Data-centric approach to establish and scale machine learning specialized into MLOps for large language models LLM.
% \url{https://blog.infocruncher.com/resources/ml-productionisation/The%20Big%20Book%20of%20MLOps%20(Databricks,%20v6,%202022).pdf}
% \url{https://docs.databricks.com/aws/en/machine-learning/mlops/mlops-workflow}

Databricks is a unified data analytics platform that integrates data engineering, data science, and machine learning workflows.

In an MLOps context, It provides an end-to-end MLOps platform with MLflow integration for experiment tracking, model registry, and deployment
Features automated CI/CD pipelines specifically optimized for ML workflows
Offers Delta Lake for reliable data management with ACID transactions
Includes feature store capabilities for feature engineering and sharing
Supports both batch and real-time serving for ML models\cite{Kreuzberger2022MachineLO, mlflow}.



== commercial example
The Databricks platform offers managed services based on
other cloud providers’ infrastructure, e.g., managed
MLflow.

\subsection{Airbyte}\label{subsec:airbyte}
Airbyte is an open-source data integration platform focused on ETL/ELT processes\cite{airbyte}.

\begin{itemize}
\item Provides pre-built connectors for data sources and destinations
\item Features a centralized configuration for data pipelines
\item Offers incremental data syncing capabilities
\item Includes data transformation capabilities using SQL and dbt
\item Integrates with data catalogs and lineage tools
\end{itemize}

While primarily a data engineering tool, Airbyte plays a crucial role in MLOps by ensuring quality data ingestion into ML pipelines.

\subsection{Argo}\label{subsec:argo}\cite{argo}
It's a suite of open-source tools for Kubernetes, designed to improve workflows, deployments, and continuous delivery.

We are particularly interested with ArgoCD and Argo Rollouts which are both mentioned in the literature\cite{inproceedings}.
Kubeflow uses Argo workflow for its pipeline orchestration capabilities.

\begin{itemize}
    \item ArgoCD
     is a declarative, GitOps-based continuous delivery tool for Kubernetes.
     It automates application deployments by syncing the desired state
     defined in a Git repository with the actual state in the cluster,
     ensuring consistency and enabling easy rollbacks.

    \item Argo Rollouts
     is a Kubernetes controller that provides advanced deployment strategies
     like canary and blue-green rollouts.
     It allows for progressive delivery, enabling safer and more controlled updates by gradually
     shifting traffic to new versions while monitoring their performance.

    \item Argo Workflow
    is a workflow orchestrator for Kubernetes.
    It's used by Kubeflow to orchestrate MLOps pipelines.
\end{itemize}

\subsection{Open-Metadata}\label{subsec:openmetadata}
Open-Metadata is a platform that can also be used to orchestrate DataOps workflow or even MLops workflow.
It depends on OpenSearch as an observability tool and Airflow for pipeline orchestration.

Airflow offers connector with OpenSearch to ease the integration of data observability and analytics component to the workflow.

\subsection{MLflow}\label{subsec:mlflow}
MLflow is an open-source platform for managing the ML lifecycle, including experimentation, reproducibility,
deployment, and a central model registry.\cite{mlflow}

MLflow provides an advanced experiment tracking functionality, a model registry, and
model serving component\cite{Kreuzberger2022MachineLO}.

\subsection{ZenML}\label{subsec:zenml}
ZenML is an extensible, open-source MLOps framework for creating portable, production-ready ML pipelines cited by\cite{blockchain-mlops}.
ZenML is designed to enable collaboration between Data Scientists, ML Engineers, and MLOps Developers throughout the development-to-production process\cite{landscape}.
It provides interfaces and abstractions specifically tailored for machine learning workflows.

\subsection{TensorFlow Extended}\label{subsec:tensorflow-extended}
TensorFlow Extended provides a library to define each tasks of an end-to-end ML
pipeline\cite{Kreuzberger2022MachineLO}.

\subsection{Dagster}\label{subsec:dagster}
Dagster is a data orchestrator designed to manage data assets like tables, ML models, and reports throughout the entire data development lifecycle—from local development to production\cite{landscape}.
It supports orchestration of various ML pipelines (e.g., feature engineering, training, batch inference) but
compared to Prefect, another orchestrator, Dagster emphasizes a full-lifecycle, first-principles approach to data engineering enabling seamless deployment across different infrastructures\cite{landscape}.
