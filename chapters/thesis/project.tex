\chapter{Thesis project: A standard MLOps/GitOps workflow}\label{ch:thesis-project:-a-standard-mlops-ci/cd-workflow}
\chaptermark{Thesis : MLOps/GitOps WorkFlow}
\section{Introduction}\label{sec:introduction}
Following our state-of-the-art research we wanted to describe and implement a standard MLOps workflow.
I should be easily used on current project to improve their level of maturity or to initiate a new project with a solid
base to be fast in production.

We don't want to create a platform, but we want to use and integrate together reviewed
tools and workflows we encountered in the literature to propose our own.

In this project, we want to apply the GitOps principle to our MLOps workflow in order to combine those two ideas together.
GitOps uses Git repositories as the main source of truce for the code, the configurations and the infrastructure.
In this matter we defined all the project within GitHub repositories to use GitHub Actions to trigger our DevOps workflow.
With the help of tools like ArgoCD, GitSync or custom scripts we also manage to trigger our DataOps and MLOps pipelines.

All our infrastructure can be deployed within one or more kubernetes clusters, depending on the actual requirements of
the ML project, this allows to define a workflow independently of hardware consideration.
Dedicated nodes with special requirements (high CPU, memory, GPU) for machine learning or data operations can be define
to run dedicated steps.
A kubernetes cluster can be deployed on premise or within the cloud depending on current infrastructure.
A single node kubernetes cluster running on the engineer laptop can be used as a development environment
within its hardware capabilities.

By combining DevOps, DataOps and MLOps pipelines with get a full MLOps workflow that can be easily deployed on any kubernetes clusters.

We will now briefly describe the tools we chose to implement our workflow squeleton.

\section{Tools}\label{sec:tools2}
In this section we will list all the tools we picked from our previous research.
As our workflow should be standard it should remain tools agnostic.

\subsection{Git Repositories and CI/CD}\label{subsec:github}
GitHub will be used to store and version control our codes repositories and configurations.
It will also be used to implement our CI/CD pipelines with GitHub actions.

\subsection{IAC, Containers and Registry}\label{subsec:dockerhub}
To benefit from containerization we will use docker to containerize our applications and models.
DockerHub will be used to store and version our Docker containers and Helm charts.

\subsection{Kubernetes}\label{subsec:kubernetes}
We will use a Kubernetes cluster to take advantage of its orchestration capabilities, advanced deployment strategies,
and the ecosystem of tools available on the platform.

\subsection{Airflow}\label{subsec:airflow}
We will use Airflow for our DataOps pipelines and to integrate our kubeflow pipelines.
We can use an Airflow DAG to trigger our Kubeflow pipelines and have a complete DataOps/MLOps pipeline while still allow respective teams
to benefit from other tools.

\subsection{Kubeflow}\label{subsec:kubeflow}
We will mainly use the storage solutions and pipelines offered by Kubeflow.
But by using kubeflow pipelines we could easily add features during the development if required by the Data or Model engineers.

\subsection{ArgoCD}\label{subsec:argocd}
ArgoCD will be used to implement our GitOps strategy and deploy our application, models, airflow and kubeflow.
We used Argo rollouts for canary deployment strategies.

\input{chapters/thesis/sections/infra}
\input{chapters/thesis/sections/roles}
\input{chapters/thesis/sections/workflow}


\section{Conclusion}\label{sec:conclusion}
Airflow pipelines and kubeflow pipelines to easily integrate DataOps and MLOps pipelines together to reach more automation as the project gains maturity.
